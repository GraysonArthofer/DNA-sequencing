{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@SRR6781412_BALB-c_mTEChi_1_4.1 1 length=160\r\n",
      "NCATCCTCCTCCTCTGAAAATTCCTCCACTTCTCGTCCTTCCTCAGGGATTTCCTGACCTGCCATTCGCAGCATCATGGCAAAAACATGAAGGAGCTGACTCCTCTTCAAGCCATGATGCTGCGAATGGCAGGTCAGGAAATCCCTGAGGAAGGACGAGA\r\n",
      "+SRR6781412_BALB-c_mTEChi_1_4.1 1 length=160\r\n",
      "#AAAAEEEEEEEEAEEEEEEEE6EEEEEEEEAEEEEEEEEEEEEEEAEEEEEEEEEEEEAEEEEEEEAEEAA/EE<EE6/AAAAAEEEEEAEAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEEEEEEEEAEEEAEEEAEEEEEEEEEEEAEEEE\r\n",
      "@SRR6781412_BALB-c_mTEChi_1_4.2 2 length=160\r\n",
      "NATCTTGTACCACTCCTACTTCGCCGTCGTCTTCTCTCTCTGCTTGCACTCCGAGAGCGTCTGGCTGTGCTGTAGCTTTTAGTAGAAGGAGATCCAAAAGTCCAAGACGGAGACGATCTCATTCCCGAGAGAGGGGTAGAAGGTCAAGGAGCACATCCAA\r\n",
      "+SRR6781412_BALB-c_mTEChi_1_4.2 2 length=160\r\n",
      "#AAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE/EAAEE/<EAA/EEEEEEE/EAEAEAEE<<E/E//E//E</AEEAAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEEEEEEEEEEEEEEEEE<EEE\r\n",
      "@SRR6781412_BALB-c_mTEChi_1_4.3 3 length=160\r\n",
      "NTCCGGGCTCGGGACATTTGTGATTTCCTGAAGGATGGGCTGTCTGCTGACCTGTCCAAGGATTGGCAGCTTCCTGACAAGAACAGTCTAAGCTAGATCCCCTCAGCAGTGCCGAAAATTCCTTGTCAGGAAGCTGCCAATCCTTTGACAGGTCAGCAGA\r\n"
     ]
    }
   ],
   "source": [
    "!head dummy_clean.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 1__ Throughout this homework you should never read the full data into RAM.  You should be able to get practice only reading the data in sequence and not reading it into memory and manipulating it that way.  Do the following in code cells between Exercise 1 and 2.\n",
    "\n",
    "1. Write some code cells that counts the number of lines in the file without loading the file in memory.\n",
    "2. Each new read begins with a sequence identifier that begins with \"@\", write a short script that counts the number of sequences.\n",
    "3. Write a def which replaces all \"T\"s to \"U\" (transcript DNA to RNA) in a sequence.  Test it on an example sequence of your choice.\n",
    "4. Write a script that looks for any anomalous reads or junk in the data that doesn't follow the basic structure above.  Clean the data and document what you did below, add the script you used to find the anomalous lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sequence begins with @, then followed by a long name, and a length tag.\n",
    "The sequence (the base calls; A, C, T, G and N), N stands for not able to read, due to insufficient quality.\n",
    "A separator, which is simply a plus (+) sign, perhaps followed by the identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of lines in the file 100000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "######NOTE: This wd will have to be changed. I couldn't figure out based on hw notes what wd to use for your setup.\n",
    "#file = open('/Users/graysonarthofer/Desktop/STA141B/Homework_1/hw1_fastq/data/dummy.fastq', 'r')\n",
    "file = open('dummy_clean.fastq', 'r')\n",
    "Counter = 0\n",
    "\n",
    "\"\"\" I created a file containing my the dataset. Then I used a for loop\n",
    "to count how many lines are in the data. The (\"\\n\") splits every new line which \n",
    "counted to collect the number of lines. Every new line increased the counter by 1\"\"\"\n",
    "\n",
    "Content = file.read()\n",
    "CoList = Content.split(\"\\n\")\n",
    "\n",
    "for i in CoList:\n",
    "    if i:\n",
    "        Counter += 1\n",
    "print(\"This is the number of lines in the file\", Counter)\n",
    "### https://www.geeksforgeeks.org/count-number-of-lines-in-a-text-file-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@SRR6781412_BALB-c_mTEChi_1_4.1 1 length=160\\nNCATCCTCCTCCTCTGAAAATTCCTCCACTTCTCGTCCTTCCTCAGGGATTTCCTGACCTGCCATTCGCAGCATCATGGCAAAAACATGAAGGAGCTGACTCCTCTTCAAGCCATGATGCTGCGAATGGCAGGTCAGGAAATCCCTGAGGAAGGACGAGA\\n+SRR6781412_BALB-c_mTEChi_1_4.1 1 length=160\\n#AAAAEEEEEEEEAEEEEEEEE6EEEEEEEEAEEEEEEEEEEEEEEAEEEEEEEEEEEEAEEEEEEEAEEAA/EE<EE6/AAAAAEEEEEAEAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEEEEEEEEAEEEAEEEAEEEEEEEEEEEAEEEE\\n@SRR6781412_BALB-c_mTEChi_1_4.2 2 length=160\\nNATCTTGTACCACTCCTACTTCGCCGTCGTCTTCTCTCTCTGCTTGCACTCCGAGAGCGTCTGGCTGTGCTGTAGCTTTTAGTAGAAGGAGATCCAAAAGTCCAAGACGGAGACGATCTCATTCCCGAGAGAGGGGTAGAAGGTCAAGGAGCACATCCAA\\n+SRR6781412_BALB-c_mTEChi_1_4.2 '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Here is a view of the raw DNA sequence data\n",
    "Content[0:650]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of sequences in the file is 25000\n"
     ]
    }
   ],
   "source": [
    "Counter = 0\n",
    "\n",
    "\"\"\"Similar method as problem 1. This time I split the file at every @ symbol which is \n",
    "the indicator of a new sequence\"\"\"\n",
    "\n",
    "CoList = Content.split(\"@\")\n",
    "for i in CoList:\n",
    "    if i:\n",
    "        Counter += 1\n",
    "print(\"The number of sequences in the file is\", Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NCAUCCUCCUCCUCUGAAAAUUCCUCCACUUCUCGUCCUUCCUCAGGGAUUUCCUGACCUGCCAUUCGCAGCAUCAUGGCAAAAACAUGAAGGAGCUGACUCCUCUUCAAGCCAUGAUGCUGCGAAUGGCAGGUCAGGAAAUCCCUGAGGAAGGACGAGA'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Transform(RNA):\n",
    "    \"\"\"Here I created a def called Transform. The function creates RNA_string which is \n",
    "    a list of the RNA. Then it iterates by the number of the dna code letter. Everytime\n",
    "    the function finds a letter T in spot i it is converted into a U. I then used ''.join\n",
    "    to get rid of the list and make the output a single string\"\"\" \n",
    "    RNA_string = list(RNA)\n",
    "    for i in range(len(RNA_string)):\n",
    "        if RNA_string[i]==\"T\": \n",
    "             RNA_string[i]=\"U\"\n",
    "    RNA = \"\".join(RNA_string)\n",
    "    return RNA\n",
    "    \n",
    "Transform(\"NCATCCTCCTCCTCTGAAAATTCCTCCACTTCTCGTCCTTCCTCAGGGATTTCCTGACCTGCCATTCGCAGCATCATGGCAAAAACATGAAGGAGCTGACTCCTCTTCAAGCCATGATGCTGCGAATGGCAGGTCAGGAAATCCCTGAGGAAGGACGAGA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to 1.4** I will begin by writing a script that checks that for every 4 lines the first line starts with @ and the third starts with +.  I use `assert` to throw an error if this does not hold and print the offending line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@SRR6781412_BALB-c_mTEChi_1_4.1 1 length=160\n",
      "\n",
      "NCATCCTCCTCCTCTGAAAATTCCTCCACTTCTCGTCCTTCCTCAGGGATTTCCTGACCTGCCATTCGCAGCATCATGGCAAAAACATGAAGGAGCTGACTCCTCTTCAAGCCATGATGCTGCGAATGGCAGGTCAGGAAATCCCTGAGGAAGGACGAGA\n",
      "\n",
      "+SRR6781412_BALB-c_mTEChi_1_4.1 1 length=160\n",
      "\n",
      "#AAAAEEEEEEEEAEEEEEEEE6EEEEEEEEAEEEEEEEEEEEEEEAEEEEEEEEEEEEAEEEEEEEAEEAA/EE<EE6/AAAAAEEEEEAEAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEEEEEEEEAEEEAEEEAEEEEEEEEEEEAEEEE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('dummy_clean.fastq','r') as reader:    \n",
    "    for i in range(4):\n",
    "        print(reader.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 2__ Quality scores are encoded as ASCII characters with the lowest being \"!\" (which has ASCII code of 33) and the highest being \"I\" (which has ASCII code of 73).  Create a def which takes in the quality character and returns a number between 0 and 1 with 0 the lowest and 1 the highest.  The function should be a linear function of the ASCII code.  (Hint: check out the `chr` and `ord` built-in functions.)  Test it out on an arbitrary sequence from the data (you can just read in the first sequence if you like).  Add this to **def quality_score** in code/fastq_reader.py, as usual add a docstring describing the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More hints, find numbers a,b such that\n",
    "```\n",
    "(ord('!') - a)/b == 0\n",
    "(ord('I') - a)/b == 1\n",
    "```\n",
    "This is your mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.8, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.525, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.8, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.8, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.8, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.8, 0.9, 0.9, 0.8, 0.8, 0.35, 0.9, 0.9, 0.675, 0.9, 0.9, 0.525, 0.35, 0.8, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9, 0.9, 0.8, 0.9, 0.8, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.8, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.8, 0.9, 0.9, 0.9, 0.8, 0.9, 0.9, 0.9, 0.8, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.8, 0.9, 0.9, 0.9, 0.9]\n"
     ]
    }
   ],
   "source": [
    "def quality_score(quality_chr):\n",
    "    \n",
    "    \"\"\"Here I interate though each element in quality_char and covert ASCII to a quality\n",
    "    score. I. subtract by the minimum score and then divide by the possible range of quality scores\"\"\"\n",
    "    \n",
    "    Quality_string = list(quality_chr)\n",
    "    for b in range(len(Quality_string)):\n",
    "        Quality_string[b] = (ord(Quality_string[b])-33)/40\n",
    "        #Char = list(Quality_string) ####is making it a list needed\n",
    "    return Quality_string\n",
    "\n",
    "x = \"#AAAAEEEEEEEEAEEEEEEEE6EEEEEEEEAEEEEEEEEEEEEEEAEEEEEEEEEEEEAEEEEEEEAEEAA/EE<EE6/AAAAAEEEEEAEAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEEEEEEEEAEEEAEEEAEEEEEEEEEEEAEEEE\"\n",
    "print(quality_score(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 3__ Write a python script that iterates through the file, and for each sequence, calculates the average quality score (as defined above).  Have the script print the sequence id for the sequence with the highest average quality, lowest average quality.  Modify code/seq_quality.py and save it over the given template.  There may be multiple sequences with the highest/lowest average quality scores, so you should just output the first sequence ID such that the average quality score is the maximum/minimum.  You should just print the sequence IDs since that is easier to identify than the sequences themselves, and the sequence ID does not need to be parsed and you can just print out the entire line starting with \"@\" containing the sequence ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function that splits the ASCII characters and the other parts\n",
    "def AvgQual(line):\n",
    "    \"\"\"Here I created a function that finds the average quality score i a given sequence.\n",
    "    I split the sequence using + symbol. I name the varibale line_quality for everything that\n",
    "    happens after the variable. Then I split line_quality again by =160 and use the variable ASCII for \n",
    "    evaluating average quality. Then I use quality score function which is defined earlier. I then\n",
    "    add up all the quality scores and divide by the number of quality scores\"\"\"\n",
    "    line_sequence, line_quality = line.strip().split(\"+\")\n",
    "    other, ASCII = line_quality.split(\"=160\") #=160 because just using 160 caused errors for lines with many 160\n",
    "    Avg_ASCII = sum(quality_score(ASCII))/len(ASCII)\n",
    "    return(Avg_ASCII)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "######NOTE: This wd will have to be changed. I couldn't figure out based on hw notes what wd to use for your setup.\n",
    "file = open('dummy_clean.fastq', 'r')\n",
    "Content = file.read()\n",
    "NewList = Content.split(\"@\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewList = NewList[1:25001] #This skips the first line which is just white space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs AvgQual function over all the list and saves the output as a list of the average quality\n",
    "Output_list = list(map(AvgQual, NewList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest quality seq: SRR6781412_BALB-c_mTEChi_1_4.68 68 length=160\n",
      "TGACGATATATGGGACCTGATCCGGGTGTCCGTGGGGACCAGGACAAAACACTCTAGACTTAACCTGAGAGATAATACTTCTTCTGTTCCGCTGAATGGCCAACTTTCAATGTGGGATGGCCTCAGGATGGTACTTTCAATTTAAGTATTATCTCTCAGG\n",
      "+SRR6781412_BALB-c_mTEChi_1_4.68 68 length=160\n",
      "AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
      " quality: 0.8846273291925489\n"
     ]
    }
   ],
   "source": [
    "##Find the maximum of average quality \n",
    "print(\"Highest quality seq:\", NewList[Output_list.index(max(Output_list))], \"quality:\", max(Output_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest quality seq: SRR6781412_BALB-c_mTEChi_1_4.22073 22073 length=160\n",
      "GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGCGGGGGGGGGGGGGGGGGGCGGGGGGGAGGGGGGGGCGGGGTTAGGGTGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGTTAGATGAAAAGTATAATG\n",
      "+SRR6781412_BALB-c_mTEChi_1_4.22073 22073 length=160\n",
      "/AAAAEEEEEEEEE/EEA6/E/A//////6//////////////////////////////////////////////////A/AAAAAE//EEEA6EAEAEAAAE/A/////66///////////////////////////////////////////////\n",
      " quality: 0.4711180124223594\n"
     ]
    }
   ],
   "source": [
    "##Find the minimum of average quality \n",
    "print(\"Highest quality seq:\", NewList[Output_list.index(min(Output_list))], \"quality:\", min(Output_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 4__ Write a python script that iterates through the file, and calculates the average quality of each of the 5 bases (A,T,G,C,N).  Print these to the screen as well, modify code/base_quality.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function that takes a list and finds all the ASCII values for all A's in the list\n",
    "\n",
    "\"\"\"Creating a def to extract all of the ASCII scores of A\n",
    "Isolating the ASCII score and the genetic sequence. Next I am \n",
    "Finding all the ASCII scores with the associated base A. Every base A\n",
    "quality score then gets appended in the the empty list ListA = [] until\n",
    "the list is full of all the ASCII scores for A\"\"\"\n",
    "def FindA(line):\n",
    "    line_sequence, line_quality = line.strip().split(\"+\")\n",
    "    extra, sequence = line_sequence.split(\"=160\")\n",
    "    other, ASCII = line_quality.split(\"=160\")#=160 because just using 160 caused errors for lines with many 160\n",
    "    ASCII = ASCII.strip()\n",
    "    sequence = sequence.strip()\n",
    "    Seq_string = list(sequence)\n",
    "    ListA = []\n",
    "    for i in range(len(sequence)):\n",
    "        if Seq_string[i] == \"A\":\n",
    "            ListA.append(ASCII[i])\n",
    "    return ListA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function that takes a list and finds all the ASCII values for all T's in the list\n",
    "def FindT(line):\n",
    "    line_sequence, line_quality = line.strip().split(\"+\")\n",
    "    extra, sequence = line_sequence.split(\"=160\")\n",
    "    other, ASCII = line_quality.split(\"=160\")#=160 because just using 160 caused errors for lines with many 160\n",
    "    ASCII = ASCII.strip()\n",
    "    sequence = sequence.strip()\n",
    "    Seq_string = list(sequence)\n",
    "    ListT = []\n",
    "    for i in range(len(sequence)):\n",
    "        if Seq_string[i] == \"T\":\n",
    "            ListT.append(ASCII[i])\n",
    "    return ListT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function that takes a list and finds all the ASCII values for all G's in the list\n",
    "def FindG(line):\n",
    "    line_sequence, line_quality = line.strip().split(\"+\")\n",
    "    extra, sequence = line_sequence.split(\"=160\")\n",
    "    other, ASCII = line_quality.split(\"=160\")#=160 because just using 160 caused errors for lines with many 160\n",
    "    ASCII = ASCII.strip()\n",
    "    sequence = sequence.strip()\n",
    "    Seq_string = list(sequence)\n",
    "    ListG = []\n",
    "    for i in range(len(sequence)):\n",
    "        if Seq_string[i] == \"G\":\n",
    "            ListG.append(ASCII[i])\n",
    "    return ListG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function that takes a list and finds all the ASCII values for all C's in the list\n",
    "def FindC(line):\n",
    "    line_sequence, line_quality = line.strip().split(\"+\")\n",
    "    extra, sequence = line_sequence.split(\"=160\")\n",
    "    other, ASCII = line_quality.split(\"=160\")#=160 because just using 160 caused errors for lines with many 160\n",
    "    ASCII = ASCII.strip()\n",
    "    sequence = sequence.strip()\n",
    "    Seq_string = list(sequence)\n",
    "    ListC = []\n",
    "    for i in range(len(sequence)):\n",
    "        if Seq_string[i] == \"C\":\n",
    "            ListC.append(ASCII[i])\n",
    "    return ListC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function that takes a list and finds all the ASCII values for all N's in the list\n",
    "def FindN(line):\n",
    "    line_sequence, line_quality = line.strip().split(\"+\")\n",
    "    extra, sequence = line_sequence.split(\"=160\")\n",
    "    other, ASCII = line_quality.split(\"=160\")#=160 because just using 160 caused errors for lines with many 160\n",
    "    ASCII = ASCII.strip()\n",
    "    sequence = sequence.strip()\n",
    "    Seq_string = list(sequence)\n",
    "    ListN = []\n",
    "    for i in range(len(sequence)):\n",
    "        if Seq_string[i] == \"N\":\n",
    "            ListN.append(ASCII[i])\n",
    "    return ListN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creates 25k lists for each base of associated ASCII values\n",
    "A = list(map(FindA, NewList))\n",
    "T = list(map(FindT, NewList))\n",
    "G = list(map(FindG, NewList))\n",
    "C = list(map(FindC, NewList))\n",
    "N = list(map(FindN, NewList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Converts the 25k lists for each base into one big list of ASCII scores for each base\n",
    "List_A = []\n",
    "for l in A:\n",
    "    List_A.extend(l)\n",
    "    \n",
    "List_T = []\n",
    "for l in T:\n",
    "    List_T.extend(l)\n",
    "\n",
    "List_G = []\n",
    "for l in G:\n",
    "    List_G.extend(l)\n",
    "    \n",
    "List_C = []\n",
    "for l in C:\n",
    "    List_C.extend(l)\n",
    "    \n",
    "List_N = []\n",
    "for l in N:\n",
    "    List_N.extend(l)\n",
    "#https://blog.finxter.com/python-list-of-lists/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(List_A)) #There are almost 1 million ASCII values for the all the A's \n",
    "List_A = ''.join(List_A) #Turns the list into a string\n",
    "List_T = ''.join(List_T)\n",
    "List_G = ''.join(List_G)\n",
    "List_C = ''.join(List_C)\n",
    "List_N = ''.join(List_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quality(Character):\n",
    "    #What to convert ASCII characters into quality scores\n",
    "    Quality_string = list(Character)\n",
    "    for b in range(len(Quality_string)):\n",
    "        Quality_string[b] = (ord(Quality_string[b])-33)/40\n",
    "    return Quality_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Def for finding the average of the ASCII score of a base\n",
    "def AvgBase(CodeList):\n",
    "    Avg_code = sum(quality_score(CodeList))/len(CodeList)\n",
    "    return Avg_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average quality of the base A is 0.8520348963034963\n",
      "The average quality of the base T is 0.8676751381936293\n",
      "The average quality of the base G is 0.8599200091092203\n",
      "The average quality of the base C is 0.8620044581858493\n",
      "The average quality of the base N is 0.05000000000000012\n"
     ]
    }
   ],
   "source": [
    "print(\"The average quality of the base A is\", AvgBase(List_A))\n",
    "print(\"The average quality of the base T is\", AvgBase(List_T))\n",
    "print(\"The average quality of the base G is\", AvgBase(List_G))\n",
    "print(\"The average quality of the base C is\", AvgBase(List_C))\n",
    "print(\"The average quality of the base N is\", AvgBase(List_N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 5__ In a sequence of tokens (such as characters in this case) an n-gram is a sequence of n tokens that follow one another in the sequence.  Fill **def ngram_freq** in code/fastq_reader.py which should take a sequence string and n as an input and output a dictionary.  This dictionary should have keys that are n-grams and values which are the frequency of that n-gram in the sequence (the percentage of all n-gram instances in the sequence which match a specific n-gram).  As an example, the 2-gram frequencies of the sequence \"TGTGCT\" are\n",
    "\n",
    "\"TG\": 2/5, \"GT\" : 1/5, \"GC\" : 1/5, \"CT\" : 1/5.\n",
    "\n",
    "Hint: it may be useful to use the Counter class in the collections package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TC': 0.4, 'CT': 0.2, 'CG': 0.2, 'GT': 0.2}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ngram_freq(sequence, n):\n",
    "    \n",
    "    \"\"\"Creating the appropriate length of y_list that is dependent of\n",
    "n. If n=1 then we would have to iterate the entire lenght of\n",
    "the sequence. Creating empty dictionary with the variable\n",
    "freq_dict. Once an ngram sequence is found then it becomes a key\n",
    "with the value of 1. Everytime the ngram is found again the \n",
    "associated key increases by 1\"\"\"\n",
    "    \n",
    "    y_list = list(range(len(sequence)-(n-1)))\n",
    "    for i in range(len(sequence)-(n-1)):\n",
    "         y_list[i] = (sequence[i:n+i])\n",
    "    freq_dict = {}\n",
    "    for i in y_list:\n",
    "        if i in freq_dict:\n",
    "            freq_dict[i] += 1\n",
    "        else:\n",
    "            freq_dict[i] = 1\n",
    "    for i in freq_dict:\n",
    "        freq_dict[i] = freq_dict[i]/len(y_list)\n",
    "    return freq_dict\n",
    "x = \"TCTCGT\"\n",
    "ngram_freq(x, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some examples,\n",
    "```\n",
    ">>> ngram_freq(\"TGCTTGC\", n=2)\n",
    "\n",
    "{'TG': 0.3333333333333333,\n",
    " 'GC': 0.3333333333333333,\n",
    " 'CT': 0.16666666666666666,\n",
    " 'TT': 0.16666666666666666}\n",
    " \n",
    ">>> ngram_freq(\"CTGAATG\", n=2)\n",
    "\n",
    "{'CT': 0.16666666666666666,\n",
    " 'TG': 0.3333333333333333,\n",
    " 'GA': 0.16666666666666666,\n",
    " 'AA': 0.16666666666666666,\n",
    " 'AT': 0.16666666666666666}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 6__ Fill in **def ngram_sim** which takes two sequences and outputs the following notion of similarity:\n",
    "$$\\sum_g \\sqrt{f(g) h(g)}$$\n",
    "where g are all n-grams in both sequences, f(g) is the frequency of g in the first sequence and h(g) is the frequency in the second.  Test this on an arbitrary pair of sequences.\n",
    "\n",
    "There are likely to be n-grams that do not occur in both sequences (but may occur in one of them).  You can start by finding only the set of n-grams that occurs in both sequences.  Then you can compute $\\sqrt{f(g) h(g)}$ for only those n-grams that are in both and sum them up.  Note that these n-grams are the intersection of the n-grams in the two sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "def ngram_sim(seq1, seq2, n=1):\n",
    "    \"\"\"Using ngram_freq to find the dictionary frequencies of seq1 and seq2 inputs. n is defined in\n",
    "    ngram_sim and is fed to ngram_freq. Dummy varibale increases after each match is found\n",
    "    and processed. Key is the name of the ngram. Each ngram in seq1_dict is interated by search though\n",
    "    seq2_dict to see if there are any matches for ngrams\"\"\"\n",
    "    seq1_dict = ngram_freq(seq1, n)\n",
    "    seq2_dict = ngram_freq(seq2, n)\n",
    "    dummy = 0\n",
    "    for key in seq1_dict:\n",
    "        if key in seq2_dict:\n",
    "            dummy = ((seq1_dict[key]*seq2_dict[key])**0.5) + dummy\n",
    "    return(dummy)\n",
    "x = \"CTGAATG\"\n",
    "y = \"CTGATTG\"\n",
    "print(ngram_sim(x, y, n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example based on the test cases above,\n",
    "```\n",
    ">>> ngf1 = ngram_freq(\"TGCTTCG\", n=2)\n",
    ">>> ngf2 = ngram_freq(\"CTGAATG\", n=2)\n",
    ">>> ngram_sim(ngf1, ngf2)\n",
    "\n",
    "0.5\n",
    "```\n",
    "We can see this because the following is true.\n",
    "```\n",
    ">>> (1/3 * 1/3)**0.5 + (1/6 * 1/6)**0.5\n",
    "\n",
    "0.5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 7__ Use regular expression and the re package to do the following.  Write a new script in code/find_re.py that uses this iterator to read through the file and print to screen the sequence identifiers with the following characteristics:\n",
    "1. The longest continuous sequence of repeated \"TCC\"s.  For example \"AGTCCTCCTCCAG\" has 3 repeats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('dummy_clean.fastq', 'r')\n",
    "Content = file.read()\n",
    "NewList = Content.split(\"@\")\n",
    "NewList = NewList[1:25001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JustSeq(line):\n",
    "    \"\"\"Strips everything except for the genetic code\"\"\"\n",
    "    line_sequence, line_quality = line.strip().split(\"+\")\n",
    "    extra, sequence = line_sequence.split(\"=160\")\n",
    "    return(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"Interates through each line in NewList. Now I have a list of just sequences\"\"\"\n",
    "Output_list = list(map(JustSeq, NewList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 'NGGGCTCATACAATAAAGCCTAGAAAGCCAATAGACATTATTGCTCATACTATTCCTCCTCCTATATAGCCGAAAGGTTCTTTTTTACATGAAACCCCCAGCCATAACACAGTATCAAACTCCACTATTTGTCTGATCCGTACTTATTACAGCCGTACTGCTCCTA'\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def FindTCC(line):\n",
    "    \"\"\"Interates through a line and assigns value based on how many consecutive \n",
    "    sequences of TCC are found. If 9 is not found then it keeps going down until \n",
    "    the highest number of consecutive sequences is found. If re.findall\n",
    "    function finds at least 1 sequence then the length of the re.finall will\n",
    "    be greater than 1. In the case that there are 10 consecutive sequences or more then the length\n",
    "    of the first argument will be met giving it a score of 9. If a score of 9 was recieved then \n",
    "    I would have had to go high to determine the highest sequence. But the highest consecutive \n",
    "    sequence was only of length 6\"\"\"\n",
    "    if len(re.findall(\"TCCTCCTCCTCCTCCTCCTCCTCCTCC\", line)) > 0:\n",
    "        line = 9\n",
    "    elif len(re.findall(\"TCCTCCTCCTCCTCCTCCTCCTCC\", line)) > 0:\n",
    "        line = 8\n",
    "    elif len(re.findall(\"TCCTCCTCCTCCTCCTCCTCC\", line)) > 0:\n",
    "        line = 7\n",
    "    elif len(re.findall(\"TCCTCCTCCTCCTCCTCC\", line)) > 0:\n",
    "        line = 6\n",
    "    elif len(re.findall(\"TCCTCCTCCTCCTCC\", line)) > 0:\n",
    "        line = 5\n",
    "    elif len(re.findall(\"TCCTCCTCCTCC\", line)) > 0:\n",
    "        line = 4\n",
    "    elif len(re.findall(\"TCCTCCTCC\", line)) > 0:\n",
    "        line = 3\n",
    "    elif len(re.findall(\"TCCTCC\", line)) > 0:\n",
    "        line = 2\n",
    "    elif len(re.findall(\"TCC\", line)) > 0:\n",
    "        line = 1\n",
    "    else:\n",
    "        line = 0\n",
    "    return(line)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq with longest TCC repeat: SRR6781412_BALB-c_mTEChi_1_4.1757 1757 length=160\n",
      "CTATTTTCTTCTTCCTCCTCCTCCTCCTCCTTCTTCATCCGGTAATACTCATCAATGGCGTACTGGTATTTTGGGGTGCTGCCACATCAACCCTCTCAGTGTGTGACTTTCTTGGAGAGAAGATTGCGTCAGTTTTGGGCATCAGCACCCCAAAATACCA\n",
      "+SRR6781412_BALB-c_mTEChi_1_4.1757 1757 length=160\n",
      "6AAAAEEEEEEEEEAAEAEAEEAEEEAEEE/EE/EEEEEEE/EE/EEEEEEEEEEE6EEEEEAA6EEEEEEEEEAAEAEAAAAAAEEEEEEEEEEEEEEEEEEE6EEEEE6EEEEEEEEEEEAEEEEEEEEEEEEEEE<AEAE<AEEAEEEAEEEEEEE/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Output_list = list(map(FindTCC, NewList))\n",
    "max(Output_list)\n",
    "#print(NewList[Output_list.index(max(Output_list))])\n",
    "\n",
    "print(\"Seq with longest TCC repeat:\", NewList[Output_list.index(max(Output_list))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the documentation for findall...\n",
    "\n",
    "re.findall(pattern, string, flags=0)\n",
    "\n",
    "Return all non-overlapping matches of pattern in string, as a list of strings. The string is scanned left-to-right, and matches are returned in the order found. If one or more groups are present in the pattern, return a list of groups; this will be a list of tuples if the pattern has more than one group. Empty matches are included in the result.\n",
    "\n",
    "We can see an example below, where we are looking for repeats of \"ba\" in a string,\n",
    "\n",
    "```\n",
    ">>> re.findall('((ba)+)','abaaababaaaba')\n",
    "\n",
    "[('ba', 'ba'), ('baba', 'ba'), ('ba', 'ba')]\n",
    "```\n",
    "\n",
    "Each element of the list is a match, and the tuples inside correspond to the groups within the pattern.  The parentheses () denote a group and so because there are two sets you obtain two groups for each match.  The first is the outer parentheses, which is the desired match."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
